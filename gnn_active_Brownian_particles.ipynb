{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import torchsde\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pbc_duplicate(x1, x2, u):\n",
    "    x1 = np.stack([x1, u[0] + x1, \n",
    "                   x1, u[0] + x1])\n",
    "    x2 = np.stack([x2, x2, \n",
    "                   u[1] + x2, u[1] + x2])\n",
    "    return x1, x2\n",
    "def cutoff_func(data):\n",
    "    return torch.where(data > torch.zeros_like(data), torch.zeros_like(data),torch.ones_like(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "# defining a DeepRitz block: f_i(s) = ϕ(Wi2 . ϕ(Wi1 . s +bi1) + bi2) + s\n",
    "class DeepRitz_block(nn.Module):\n",
    "    def __init__(self, h_size):\n",
    "        super(DeepRitz_block, self).__init__()\n",
    "        self.dim_h = h_size\n",
    "\n",
    "        self.activation_function = nn.ReLU()\n",
    "        block = [nn.Linear(self.dim_h, self.dim_h),\n",
    "                 self.activation_function,\n",
    "                 nn.Linear(self.dim_h, self.dim_h),\n",
    "                 self.activation_function]\n",
    "        self._block = nn.Sequential(*block)\n",
    "    def forward(self, x):\n",
    "        return self._block(x) + x\n",
    "\n",
    "# defining the neural network constructed by DeepRitz blocks\n",
    "class Neural_Network(nn.Module):\n",
    "    def __init__(self, in_size=1, h_size = 10, block_size = 1, cutoff_distance = 4., theta=0., dev=\"cpu\"):\n",
    "        super(Neural_Network, self).__init__()\n",
    "        self.num_blocks = block_size\n",
    "        self.in_size = in_size\n",
    "        self.dim_h = h_size\n",
    "        self.dev = dev\n",
    "        self.CUTOFF = cutoff_distance\n",
    "        self.theta = theta\n",
    "        \n",
    "        # assemble the neural network with DeepRitz blocks\n",
    "        self._block0 = DeepRitz_block(self.dim_h)\n",
    "        self._block = DeepRitz_block(self.dim_h)\n",
    "        \n",
    "        model_t = [nn.ConstantPad1d((0, self.dim_h - self.in_size), 0)]\n",
    "        for _ in range(2):\n",
    "            model_t.append(self._block0)\n",
    "        model_t.append(nn.Linear(self.dim_h, 1))\n",
    "        self._model_t = nn.Sequential(*model_t)\n",
    "        \n",
    "        model0 = [nn.ConstantPad1d((0, self.dim_h - self.in_size), 0)]\n",
    "        for _ in range(2):\n",
    "            model0.append(self._block0)\n",
    "        self.fe = nn.Sequential(*model0)\n",
    "\n",
    "        model = []\n",
    "        for _ in range(self.num_blocks):\n",
    "            model.append(self._block)\n",
    "        model.append(nn.Linear(self.dim_h, 2))\n",
    "        self.fg = nn.Sequential(*model)\n",
    "        \n",
    "    def rotation(self, dx):\n",
    "        th = self._model_t(dx) + self.theta\n",
    "        rotation = torch.cat([torch.cos(th), -torch.sin(th), torch.sin(th),  torch.cos(th)],-1)\n",
    "        return rotation.view([*th.shape[:-1],2,2])\n",
    "\n",
    "    def decay(self, dx):\n",
    "        return (torch.cos(np.pi * dx/self.CUTOFF) + 1.).pow(1/2)\n",
    "        \n",
    "    # the magnitude of the control force\n",
    "    def forward(self, dx):\n",
    "        y =  self.fe(dx) * cutoff_func(dx[...,:1]-self.CUTOFF) * self.decay(dx[...,:1])\n",
    "        y = self.fg(y[...,1:,:].sum(-2))\n",
    "        return y\n",
    "\n",
    "# defining the dynamical system of interests: dX_t = F(X_t)dt + \\sqrt{2\\epsilon}dW_t\n",
    "# active Brownian particles\n",
    "class ODE(nn.Module):\n",
    "    def __init__(self, num_particles, v, unit_size, dev):\n",
    "        super().__init__()\n",
    "        self.dev = dev\n",
    "        self.epsilon = 1.\n",
    "        self.dim_r = num_particles\n",
    "        self.unit_size = unit_size\n",
    "        self.v = v\n",
    "\n",
    "        self.corrector = 2**(1/3)*torch.eye(num_particles).to(dev)\n",
    "\n",
    "    def F(self, theta, dX1, dX2):\n",
    "        dis = dX1**2 + dX2**2 + self.corrector.expand([*theta.shape[:-1], self.dim_r,self.dim_r])\n",
    "        \n",
    "        dU = torch.relu(dis**(-13/2) - 1/2 * dis**(-7/2))\n",
    "        \n",
    "        F1 = 48.*self.epsilon * (dU * dX1).sum(-1) + self.v * torch.cos(theta)\n",
    "        F2 = 48.*self.epsilon * (dU * dX2).sum(-1) + self.v * torch.sin(theta)\n",
    "        \n",
    "        return torch.cat([F1, F2, torch.zeros(F1.shape).to(self.dev)], -1)\n",
    "    \n",
    "    def forward(self, theta, dX1, dX2):\n",
    "        return self.F(theta, dX1, dX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the SDE with trial driven force u(x) and fixed diffusion matrix D\n",
    "class SDE(nn.Module):\n",
    "    sde_type = 'stratonovich'\n",
    "#     sde_type = 'ito'\n",
    "    noise_type = 'general'\n",
    "\n",
    "    def __init__(self, Drift, Diffusion, num_neighbor, unit_size, dev = \"cpu\"):\n",
    "        super(SDE, self).__init__()\n",
    "        self.dev = dev\n",
    "        self.dim_x = Diffusion.size(1)\n",
    "        self.num_neighbor = num_neighbor\n",
    "        self.unit_size = unit_size\n",
    "        self.dim_x_ABP = int(2/3*self.dim_x)\n",
    "        self.dim_r = self.dim_x//3\n",
    "\n",
    "        # drift & const diffusion matrix D:\n",
    "        self._drift_0 = Drift.to(dev)\n",
    "        self._diffusion = Diffusion.to(dev)\n",
    "        self.eyes = torch.eye(self.dim_r, self.dim_r).to(dev)\n",
    "        self.gamma = 1.\n",
    "        \n",
    "    def MIC(self, x, axis=0):\n",
    "        return (x + self.unit_size[axis]/2) % self.unit_size[axis] - self.unit_size[axis]/2\n",
    "    \n",
    "    def PBC(self, x):\n",
    "        x[...,:self.dim_r] = x[...,:self.dim_r] % self.unit_size[0]\n",
    "        x[...,self.dim_r:2*self.dim_r] = x[...,self.dim_r:2*self.dim_r] % self.unit_size[1]\n",
    "        x[...,self.dim_x_ABP:] = x[...,self.dim_x_ABP:] % (2 * np.pi)\n",
    "        return x\n",
    "    \n",
    "    def NN_input(self, x):\n",
    "        X1 = x[...,:self.dim_r].unsqueeze(-1).expand(*x.shape[:-1],self.dim_r,self.dim_r).transpose(-1,-2)\n",
    "        X2 = x[...,self.dim_r:2*self.dim_r].unsqueeze(-1).expand(*x.shape[:-1],self.dim_r,self.dim_r).transpose(-1,-2)\n",
    "        dX1 = self.MIC(X1.transpose(-1,-2)-X1, 0)\n",
    "        dX2 = self.MIC(X2.transpose(-1,-2)-X2, 1)\n",
    "        D = torch.sqrt(dX1**2 + dX2**2)\n",
    "        index = torch.argsort(D)[...,:self.num_neighbor]\n",
    "        D[D > CUTOFF] = 0.\n",
    "        return dX1, dX2, torch.gather(D,-1,index)[...,None], index\n",
    "    \n",
    "    def control_force(self, dX1, dX2, dx, index):\n",
    "        dX1 = torch.gather(dX1,-1,index)\n",
    "        dX2 = torch.gather(dX2,-1,index)\n",
    "        D = torch.sqrt(dX1.pow(2) + dX2.pow(2))\n",
    "        rot = neural_network.rotation(dx)\n",
    "        direction = torch.stack([(dX1/(D+1e-9)), (dX2/(D+1e-9))],-1)\n",
    "#         direction = torch.einsum('...ij,...j->...i', rot, direction)\n",
    "        F = neural_network(dx) * direction.sum(-2)\n",
    "        return F\n",
    "    \n",
    "    # the trial driven force u(x)\n",
    "    def drift(self, t, x):\n",
    "        x = self.PBC(x)\n",
    "        dX1, dX2, dx, index = self.NN_input(x)\n",
    "        F0 = self._drift_0(x[...,self.dim_x_ABP:], dX1, dX2)\n",
    "        F = self.control_force(dX1, dX2, dx, index)\n",
    "        F = torch.cat([F[...,0], F[...,1], torch.zeros([*x.shape[:-1], self.dim_r]).to(dev)], -1)\n",
    "        return F + F0\n",
    "\n",
    "    # the diffusion matrix\n",
    "    def diffusion(self, t, x):\n",
    "        return self._diffusion.expand(x.size(0), self.dim_x, self.dim_x)\n",
    "\n",
    "    # the F(x)\n",
    "    def drift_0(self, t, x):\n",
    "        x = self.PBC(x)\n",
    "        dX1, dX2, dx, index = self.NN_input(x)\n",
    "        F0 = self._drift_0(x[...,self.dim_x_ABP:], dX1, dX2)\n",
    "        return F0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighbor, dim_h, num_blocks = 20+1, 10, 1\n",
    "dim_x, aspect, rho, v = 400, 1, .6, 100\n",
    "CUTOFF = 3.5\n",
    "\n",
    "unit_size = np.sqrt(dim_x / rho) + 0.0001\n",
    "unit_size = np.array([unit_size * np.sqrt(aspect), unit_size / np.sqrt(aspect)])\n",
    "\n",
    "dev = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(dev)\n",
    "\n",
    "neural_network = Neural_Network(1, dim_h, num_blocks, CUTOFF, 0., dev).to(dev)\n",
    "\n",
    "Dt = 1.\n",
    "Dr = 3.*Dt\n",
    "diffusion = torch.tensor( np.sqrt(2 * np.kron(np.diag([Dt, Dt, Dr]), np.eye(dim_x))) ).float().to(dev)\n",
    "\n",
    "ode = ODE(dim_x, v, unit_size, dev)\n",
    "sde = SDE(ode, diffusion, num_neighbor, unit_size, dev).to(dev)\n",
    "if sde.sde_type == 'ito':\n",
    "    sde_method = 'euler'\n",
    "else:\n",
    "    sde_method = 'midpoint'\n",
    "Lambda_k = []\n",
    "A_k = []\n",
    "K_k = []\n",
    "swaps_k = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = .08e-4\n",
    "batch_size = 10\n",
    "biasing = -12.\n",
    "\n",
    "X, Y = np.meshgrid(np.arange(20)/20 * unit_size[0], np.arange(20)/35 * unit_size[1])\n",
    "x0 = torch.cat([torch.rand([batch_size, dim_x]) * unit_size[0],\n",
    "                torch.rand([batch_size, dim_x]) * unit_size[1],\n",
    "                torch.rand([batch_size, dim_x]) * 2 * np.pi],-1).to(dev)\n",
    "x0[:,:2*dim_x] = torch.tensor(np.hstack([X.flatten() * 1., Y.flatten()])).to(dev)\n",
    "with torch.no_grad():\n",
    "    x_init = torchsde.sdeint(sde, x0.to(dev), torch.arange(0, 100 * dt, dt).to(dev), dt = dt,\n",
    "                             method=sde_method, names={'drift': 'drift_0', 'diffusion': 'diffusion'})[-1]\n",
    "\n",
    "optimizer = torch.optim.Adagrad(neural_network.parameters(), lr = 1e-2)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = 20 * dt\n",
    "ts = torch.arange(0, T+dt, dt).to(dev)\n",
    "\n",
    "step = 0\n",
    "while step < 300:\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        traj = torchsde.sdeint(sde, x_init.to(dev), ts, dt = dt,\n",
    "                               method=sde_method, names={'drift': 'drift', 'diffusion': 'diffusion'})\n",
    "        x_init = traj[-1].detach()\n",
    "\n",
    "        dX1, dX2, dx, index = sde.NN_input(traj)\n",
    "        F0 = ode(traj[..., 2*dim_x:], dX1, dX2)[:-1,:,:2*dim_x]\n",
    "        b = torch.cat([torch.cos(traj[...,2*dim_x:]), torch.sin(traj[...,2*dim_x:])], 2)\n",
    "        b_mid = (b[1:,]+b[:-1])/2\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    F = sde.control_force(dX1, dX2, dx, index)[:-1]\n",
    "    F = torch.cat([F[...,0], F[...,1]],-1)\n",
    "\n",
    "    K_T = torch.sum(F**2, (0,-1))/Dt/2 *dt/T\n",
    "    A_T = v/Dt * torch.sum(b_mid * (F + F0), (0,-1)) *dt/T\n",
    "    \n",
    "    loss_batch = (K_T - biasing * A_T) / dim_x\n",
    "        \n",
    "    loss_batch.mean().backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    K_k.append(K_T.cpu().detach().numpy().flatten()/ dim_x)\n",
    "    A_k.append(A_T.cpu().detach().numpy().flatten()/ dim_x)\n",
    "    Lambda_k.append(biasing * A_k[-1] - K_k[-1])\n",
    "    step += 1\n",
    "\n",
    "    t_simul = time.time()\n",
    "    print('%i - %.2f sec - loss: %.4f - %.4f * %.4f = %.4f' \n",
    "            % (step, float(t_simul-start_time), np.mean(K_k[-1]), biasing, \n",
    "               np.mean(A_k[-1]), np.mean(Lambda_k[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(18,3))\n",
    "psi = np.array(Lambda_k).mean(-1)\n",
    "observable = np.array(A_k).mean(-1)\n",
    "ax[0].plot(psi)\n",
    "ax[1].plot(np.array(K_k).mean(-1))\n",
    "ax[2].plot(observable)\n",
    "\n",
    "ax[0].set_ylabel(r'$\\psi(\\lambda)$')\n",
    "ax[1].set_ylabel(r'$D_{KL}$')\n",
    "ax[2].set_ylabel(r'$A_T$')\n",
    "for i in range(3):\n",
    "    ax[i].grid()\n",
    "    ax[i].set_xlabel('training steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0\n",
    "scale = 1000\n",
    "fig_snapshot, ax = plt.subplots(figsize=(10,6))\n",
    "ax.set_aspect(1)\n",
    "x = traj[-1,b,:dim_x].cpu().detach().numpy()\n",
    "y = (traj[-1,b,dim_x:dim_x*2].cpu().detach().numpy() + 4) % unit_size[1]\n",
    "Fx = F[-1,b,:dim_x].cpu().detach().numpy()\n",
    "Fy = F[-1,b,dim_x:].cpu().detach().numpy()\n",
    "\n",
    "ax.scatter(x,y,s=200*200/dim_x, alpha=0.5, c='steelblue',linewidths=1.2)\n",
    "ax.quiver(x,y, Fx, Fy, scale_units='height')\n",
    "ax.set_xlim([0, unit_size[0]])\n",
    "ax.set_ylim([0, unit_size[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
